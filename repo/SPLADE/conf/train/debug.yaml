batch_size: 128
per_device_batch_size: 32
gradient_accumulation_steps: 1

learning_rate: 2e-5
weight_decay: 0.01
max_epochs:

max_steps: 1000 # Debug setting (original: 150000)
val_check_interval: 1000  # In general, 5000

# Regularizer settings
FLOPS:
  lambda_q: 3e-4
  lambda_p: 1e-4
  T: 50000

warmup_steps: 100