batch_size: 128
per_device_batch_size: 32
gradient_accumulation_steps: 1

learning_rate: 1e-5
weight_decay: 0.0
max_epochs: 5